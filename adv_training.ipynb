{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "adv_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2g7ZqSKC5Pke"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')           \n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "input_shape = (28, 28, 1)\n",
        "num_classes = 10\n",
        "VALIDATION_SPLIT = 0.1\n",
        "BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\nLoading MNIST')\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_train = x_train.astype(np.float32) / 255\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "x_test = x_test.astype(np.float32) / 255\n",
        "\n",
        "mnist_twos = x_train[np.where(y_train == 2)][:10]\n",
        "\n",
        "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print('\\nSpliting data')\n",
        "\n",
        "ind = np.random.permutation(x_train.shape[0])\n",
        "x_train, y_train = x_train[ind], y_train[ind]\n",
        "n = int(x_train.shape[0] * (1-VALIDATION_SPLIT))\n",
        "x_train = x_train[:n]\n",
        "y_train = y_train[:n]\n",
        "x_val = x_train[n:]\n",
        "y_val = y_train[n:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghc5cAZ65lYI",
        "outputId": "f40802de-95d4-4d57-b519-e034641d48b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading MNIST\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "\n",
            "Spliting data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print('\\nConstructing model')\n",
        "def make_model(input_shape, num_classes):\n",
        "    inputs = keras.Input(shape = input_shape)\n",
        "    x = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')(inputs)\n",
        "    x = keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
        "    x = keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(x)\n",
        "    x = keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
        "    x = keras.layers.Flatten()(x)\n",
        "    x = keras.layers.Dense(units=128, activation='relu')(x)\n",
        "    x = keras.layers.Dropout(0.25)(x)\n",
        "    outputs = keras.layers.Dense(units=num_classes)(x)\n",
        "    #outputs = keras.layers.Activation('relu')\n",
        "    return keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cooBNa35q-G",
        "outputId": "6bf077a8-9ac8-4164-f500-04eda78cc1ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(54000,)\n",
            "(10000,)\n",
            "\n",
            "Constructing model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uVH_jPHhHIOx"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn = make_model(input_shape, num_classes)\n",
        "X_train = []\n",
        "X_test = []\n",
        "begin = 0\n",
        "\n",
        "\n",
        "for i in range(0, x_train.shape[0] , 100):\n",
        "  X_train.append((x_train[i:i+100],y_train[i:i+100]))\n",
        "  \n",
        "\n",
        "for i in range(0, x_test.shape[0] , 100):\n",
        "  X_test.append((x_train[i:i+100],y_test[i:i+100]))\n",
        "print(y_train.shape)\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits = True)"
      ],
      "metadata": {
        "id": "w2A0B3Qy8gvd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d44e97d7-bcba-4f59-b959-0b315b4d090d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(54000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fgsm(model, X, y, epsilon=0.1):\n",
        "    \"\"\" Construct FGSM adversarial examples on the examples X\"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "      tape.watch(X)\n",
        "      #prediction = model.predict(X)\n",
        "      #print(type(y))\n",
        "      loss = loss_fn(y,model(X))\n",
        "      #print(type(loss))\n",
        "    gradient = tape.gradient(loss, X)\n",
        "    signed_gradient = tf.sign(gradient)\n",
        "    #print(gradient.shape)\n",
        "    return epsilon*signed_gradient\n",
        "\n",
        "  \n",
        "'''\n",
        "def pgd_linf(model, X, y, epsilon=0.1, alpha=0.01, num_iter=20, randomize=False):\n",
        "    \"\"\" Construct FGSM adversarial examples on the examples X\"\"\"\n",
        "    if randomize:\n",
        "        delta = np.random.randn(X.shape)\n",
        "        delta = delta* 2 * epsilon - epsilon\n",
        "    else:\n",
        "        delta = np.zeros(X.shape)\n",
        "    \n",
        "    for t in range(num_iter):\n",
        "      with tf.GradientTape() as tape: \n",
        "        tf.\n",
        "    for t in range(num_iter):\n",
        "        loss = nn.CrossEntropyLoss()(model(X + delta), y)\n",
        "        loss.backward()\n",
        "        delta.data = (delta + alpha*delta.grad.detach().sign()).clamp(-epsilon,epsilon)\n",
        "        delta.grad.zero_()\n",
        "    return delta.detach()\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "rpifNBlF5w4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch(model , X, loss_fn , optimizer):\n",
        "  total_loss,total_error = 0.,0.\n",
        "  for x,y in X :\n",
        "    with tf.GradientTape() as tape:\n",
        "      yp = model(x, training = True)\n",
        "      #print(\"yp =\" , yp.shape)\n",
        "      #print(\"y = \" , y.shape)\n",
        "      loss_value = loss_fn(y, yp)\n",
        "      #print(type(loss_value))\n",
        "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    total_error += np.sum(np.argmax(yp,axis = 1)!=1)\n",
        "    total_loss += loss_value*len(X)\n",
        "    return total_error / len(X), total_loss /len(X)\n",
        "\n",
        "def epoch_adversarial(model, X ,loss_fn, optimizer):\n",
        "  total_loss,total_error = 0.,0.\n",
        "  for x,y in X :\n",
        "    delta = fgsm(model, tf.convert_to_tensor(x) , y)\n",
        "    with tf.GradientTape() as tape:\n",
        "      yp = model(x + delta, training = True)\n",
        "      loss_value = loss_fn(y, yp)\n",
        "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    total_error += np.sum(np.argmax(yp,axis = 1)!=1)\n",
        "    total_loss += loss_value*len(X)\n",
        "    return total_error / len(X), total_loss /len(X) "
      ],
      "metadata": {
        "id": "6E9e2VFRQnAl"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate = 0.2)\n",
        "for t in range(10):\n",
        "  train_err, train_loss = epoch(model_cnn, X_train,loss_fn,optimizer)\n",
        "  test_err, test_loss = epoch(model_cnn, X_test,loss_fn,optimizer)\n",
        "  adv_err, adv_loss = epoch_adversarial(model_cnn,X_test,loss_fn,optimizer)\n",
        "  if(t == 4):\n",
        "    optimizer.learning_rate = 1e-2\n",
        "  print(*(\"{:.6f}\".format(i) for i in (train_err, test_err, adv_err)), sep=\"\\t\")\n",
        "  \n",
        "\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTlfgKT4f6n8",
        "outputId": "b84e062a-033d-47d3-dfde-b54d50c00f80"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.088889\t0.470000\t0.460000\n",
            "0.075926\t0.620000\t0.440000\n",
            "0.074074\t0.520000\t0.530000\n",
            "0.064815\t0.600000\t0.400000\n",
            "0.070370\t0.430000\t0.370000\n",
            "0.033333\t0.270000\t0.250000\n",
            "0.027778\t0.240000\t0.380000\n",
            "0.031481\t0.180000\t0.250000\n",
            "0.042593\t0.270000\t0.240000\n",
            "0.044444\t0.220000\t0.190000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn_robust = make_model(input_shape, num_classes)\n"
      ],
      "metadata": {
        "id": "NkKegWDu6k2n"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_robust = tf.keras.optimizers.Adam(learning_rate = 0.1)\n",
        "for t in range(10):\n",
        "    train_err, train_loss = epoch_adversarial(model_cnn_robust, X_train,loss_fn,optimizer_robust)\n",
        "    test_err, test_loss = epoch(model_cnn_robust, X_test,loss_fn,optimizer_robust)\n",
        "    adv_err, adv_loss = epoch_adversarial(model_cnn_robust,X_test,loss_fn, optimizer_robust)\n",
        "    if(t == 4):\n",
        "      optimizer_robust.learning_rate = 1e-2\n",
        "    print(*(\"{:.6f}\".format(i) for i in (train_err, test_err, adv_err)), sep=\"\\t\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVFu8IUz9WFs",
        "outputId": "25a579bc-7b01-4721-c423-d02e0e2eac95"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.177778\t0.900000\t0.920000\n",
            "0.175926\t0.730000\t0.910000\n",
            "0.170370\t0.640000\t0.740000\n",
            "0.129630\t0.720000\t0.680000\n",
            "0.135185\t0.530000\t0.680000\n",
            "0.120370\t0.390000\t0.570000\n",
            "0.114815\t0.430000\t0.650000\n",
            "0.120370\t0.410000\t0.600000\n",
            "0.092593\t0.460000\t0.570000\n",
            "0.101852\t0.560000\t0.560000\n"
          ]
        }
      ]
    }
  ]
}